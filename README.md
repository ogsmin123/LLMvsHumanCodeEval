# LLMvsHumanCodeEval
This framework performs an **empirical evaluation** comparing *pre-LLM human code* and *AI-generated code* for algorithmic problems.
